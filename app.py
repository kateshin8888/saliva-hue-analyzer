import numpy as np
import streamlit as st
import cv2
from analyzer import analyze_well_image

# -------------------------
# Config
# -------------------------
st.set_page_config(
    page_title="SalivaID (Prototype)",
    page_icon="ğŸ§ª",
    layout="centered",
)

STEPS = ["start", "input", "analyze", "result"]
STEP_LABEL = {
    "start": "Start",
    "input": "Input",
    "analyze": "Analyze",
    "result": "Result",
}

# -------------------------
# Session state init
# -------------------------
if "step" not in st.session_state:
    st.session_state.step = "start"

def goto(step: str):
    if step not in STEPS:
        step = "start"
    st.session_state.step = step
    st.rerun()

def reset_all(to_step: str = "start"):
    st.session_state.pop("uploaded_file_bytes", None)
    st.session_state.pop("uploaded_file_name", None)
    st.session_state.pop("result", None)
    goto(to_step)

def reset_to_input():
    reset_all(to_step="input")


# -------------------------
# Small UI helper (progress + header)
# -------------------------
def render_step_header():
    step = st.session_state.step
    idx = STEPS.index(step) if step in STEPS else 0
    st.progress((idx + 1) / len(STEPS))
    st.caption(f"Step {idx + 1}/4 Â· {STEP_LABEL.get(step, 'Start')}")


# -------------------------
# Step 1: Start
# -------------------------
def render_start():
    render_step_header()

    st.title("ğŸ§ª SalivaID")
    st.write("í•œ ì¥ì˜ ì‚¬ì§„ìœ¼ë¡œ wellì˜ ìƒ‰ ë³€í™”(Hue)ë¥¼ ë¶„ì„í•˜ëŠ” ì—°êµ¬ìš© í”„ë¡œí† íƒ€ì…ì…ë‹ˆ ë‹¤.")
    st.info("ì¤‘ìš”: ë³¸ ì•±ì€ ì˜ë£Œì  ì§„ë‹¨ ë„êµ¬ê°€ ì•„ë‹ˆë©°, ì—°êµ¬/êµìœ¡ ëª©ì ì˜ ìƒ‰ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

    st.markdown("**ì‚¬ìš© ë°©ë²•(1ì¤„):** ì‚¬ì§„ ì—…ë¡œë“œ â†’ ë¶„ì„ â†’ threshold ë¹„êµ ê²°ê³¼ í™•ì¸")

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
            goto("input")
    with col2:
        if st.button("ë¦¬ì…‹", use_container_width=True):
            reset_all("start")

    with st.expander("ì´¬ì˜ ê°€ì´ë“œ(ê¶Œì¥)", expanded=True):
        st.markdown(
            "- ë™ì¼í•œ ì¡°ëª…(ë¼ì´íŠ¸ë°•ìŠ¤/ê³ ì • ì¡°ëª… ê¶Œì¥)\n"
            "- ê·¸ë¦¼ì/ë°˜ì‚¬(ê¸€ë ˆì–´) ìµœì†Œí™”\n"
            "- ì´ˆì  ì„ ëª…(í”ë“¤ë¦¼ X)\n"
            "- wellì´ í”„ë ˆì„ ì¤‘ì•™ì— ì˜¤ë„ë¡"
        )


# -------------------------
# Step 2: Input
# -------------------------
def render_input():
    render_step_header()

    st.header("ì‚¬ì§„ ì—…ë¡œë“œ")
    st.caption("ì‚¬ì§„ ì—…ë¡œë“œ í›„ â€˜ë¶„ì„í•˜ê¸°â€™ë¥¼ ëˆŒëŸ¬ì•¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°‘ë‹ˆ ë‹¤.")

    with st.form("upload_form", clear_on_submit=False):
        uploaded_file = st.file_uploader(
            "Upload an image (JPG/PNG)",
            type=["jpg", "jpeg", "png"],
        )
        submitted = st.form_submit_button("ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True)

    if uploaded_file is not None:
        st.subheader("Preview")
        st.image(uploaded_file, caption=uploaded_file.name, use_column_width=True)

    if submitted:
        if uploaded_file is None:
            st.error("ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ ìš”.")
            st.stop()

        st.session_state.uploaded_file_bytes = uploaded_file.read()
        st.session_state.uploaded_file_name = uploaded_file.name
        goto("analyze")

    # âœ… ì—¬ê¸°ì„œ ë°˜ë“œì‹œ col1/col2 ë‘˜ ë‹¤ withë¡œ ë‹«ì•„ì¤˜ì•¼ í•¨
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ì‹œì‘ í™”ë©´", use_container_width=True):
            goto("start")
    with col2:
        if st.button("ì…ë ¥ ì´ˆê¸°í™”", use_container_width=True):
            reset_to_input()


# -------------------------
# Step 3: Analyze
# -------------------------
def render_analyze():
    render_step_header()

    st.header("ë¶„ì„ ì¤‘")
    st.caption("ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆ ë‹¤...")

    file_bytes = st.session_state.get("uploaded_file_bytes")
    if not file_bytes:
        st.warning("ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ë‹¨ê³„ë¡œ ì´ë™í•©ë‹ˆ ë‹¤.")
        goto("input")

    try:
        with st.spinner("Analyzing image..."):
            result = analyze_well_image(file_bytes)

        st.session_state.result = result
        goto("result")

    except Exception as e:
        st.error(f"Error during analysis: {e}")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ë‹¤ì‹œ ì—…ë¡œë“œ", type="primary", use_container_width=True):
                reset_to_input()
        with col2:
            if st.button("ì‹œì‘ í™”ë©´", use_container_width=True):
                reset_all("start")


# -------------------------
# Step 4: Result
# -------------------------
def render_result():
    render_step_header()

    st.header("ê²°ê³¼")
    result = st.session_state.get("result")
    if result is None:
        st.warning("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¶„ì„í•´ì£¼ì„¸ ìš”.")
        if st.button("ì—…ë¡œë“œë¡œ ëŒì•„ê°€ê¸°", type="primary", use_container_width=True):
            reset_to_input()
        return

    avg_h_cv = result.get("avg_h_cv")
    avg_h_deg = result.get("avg_h_deg")
    threshold_deg = result.get("threshold_deg")
    threshold_cv = result.get("threshold_cv")
    above_threshold = result.get("above_threshold")
    img_bgr = result.get("img_bgr")

    img_rgb = None
    if img_bgr is not None:
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    if above_threshold:
        st.warning(
            "**Above threshold**\n\n"
            "ìƒ‰ ë³€í™”ê°€ ì„ê³„ê°’ë³´ë‹¤ í½ë‹ˆ ë‹¤. ì´¬ì˜ ì¡°ê±´ì„ ì ê²€í•œ ë’¤ ì¬ì¸¡ì •/ì¶”ê°€ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆ ë‹¤."
        )
    else:
        st.success(
            "**Below threshold**\n\n"
            "ìƒ‰ ë³€í™”ê°€ ì„ê³„ê°’ë³´ë‹¤ ì‘ìŠµë‹ˆ ë‹¤. ë‹¨, ì´¬ì˜ ì¡°ê±´(ì¡°ëª…/ì´ˆì /ë°˜ì‚¬)ì— ë”°ë¼ ê°’ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆ ë‹¤."
        )

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Key metrics")
        st.metric("Average Hue (deg)", f"{avg_h_deg:.2f}" if avg_h_deg is not None else "N/A")
        st.metric("Threshold (deg)", f"{threshold_deg:.2f}" if threshold_deg is not None else "N/A")

        with st.expander("Show technical details"):
            st.write(
                f"**Average Hue (OpenCV 0â€“179):** `{avg_h_cv:.2f}`"
                if avg_h_cv is not None else
                "**Average Hue (OpenCV 0â€“179):** N/A"
            )
            st.write(
                f"**Threshold Hue (OpenCV):** `{threshold_cv:.2f}`"
                if threshold_cv is not None else
                "**Threshold Hue (OpenCV):** N/A"
            )

    with col2:
        st.subheader("Image used")

        # âœ… ì˜¤ë²„ë ˆì´ëŠ” result/img_bgr/img_rgbê°€ ì¡´ì¬í•˜ëŠ” ì—¬ê¸°(render_result) ì•ˆì—ì„œë§Œ ê°€ëŠ¥
        mask = result.get("mask", None)
        roi_bbox = result.get("roi_bbox", None)

        overlay_rgb = None
        used_pct = None

        if img_bgr is not None and (mask is not None or roi_bbox is not None):
            try:
                overlay_bgr = img_bgr.copy()

                if mask is not None:
                    if len(mask.shape) == 3:
                        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    else:
                        mask_gray = mask

                    if mask_gray.shape[:2] != overlay_bgr.shape[:2]:
                        mask_gray = cv2.resize(
                            mask_gray,
                            (overlay_bgr.shape[1], overlay_bgr.shape[0]),
                            interpolation=cv2.INTER_NEAREST,
                        )

                    mask_bin = mask_gray > 0
                    used_pct = float(np.mean(mask_bin) * 100.0)

                    color = np.zeros_like(overlay_bgr)
                    color[:] = (0, 255, 0)

                    blended = cv2.addWeighted(overlay_bgr, 0.55, color, 0.45, 0)
                    overlay_bgr[mask_bin] = blended[mask_bin]

                if roi_bbox is not None and len(roi_bbox) == 4:
                    x, y, w, h = roi_bbox
                    cv2.rectangle(overlay_bgr, (x, y), (x + w, y + h), (0, 255, 255), 2)

                overlay_rgb = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)

            except Exception:
                overlay_rgb = None

        tab1, tab2 = st.tabs(["Original", "ROI/Mask overlay"])

        with tab1:
            if img_rgb is not None:
                st.image(img_rgb, caption="Original image", use_column_width=True)
            else:
                st.info("í‘œì‹œí•  ì›ë³¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with tab2:
            if overlay_rgb is not None:
                st.image(overlay_rgb, caption="Pixels used for hue computation", use_column_width=True)
                if used_pct is not None:
                    st.caption(f"Used pixels: {used_pct:.1f}%")
            else:
                st.info("mask/ROI ì •ë³´ê°€ ì—†ì–´ ì˜¤ë²„ë ˆì´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("How to interpret this"):
        td = f"{threshold_deg:.2f}" if threshold_deg is not None else "N/A"
        st.write(
            "- HueëŠ” ì¶©ë¶„í•œ saturation/brightnessë¥¼ ê°€ì§„ í”½ì…€ì—ì„œ ê³„ì‚°ë©ë‹ˆë‹¤.\n"
            f"- ThresholdëŠ” ì‹¤í—˜ì  calibration ê°’ì—ì„œ ë„ì¶œë©ë‹ˆë‹¤. (ì˜ˆ: `{td}`Â°)\n"
            "- Above thresholdëŠ” ìƒ‰ ë³€í™”ê°€ ë” ê°•í•˜ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\n\n"
            "**Important:** ë³¸ ê²°ê³¼ëŠ” ì—°êµ¬/êµìœ¡ ëª©ì ì˜ ìƒ‰ ë¶„ì„ì´ë©°, ì˜ë£Œì  ì§„ë‹¨ì´ ì•„ë‹™ë‹ˆë‹¤."
        )

    st.subheader("Next actions")
    a1, a2, a3 = st.columns(3)
    with a1:
        if st.button("ë‹¤ë¥¸ ì´ë¯¸ì§€ ë¶„ì„", type="primary", use_container_width=True):
            reset_to_input()
    with a2:
        if st.button("ì…ë ¥ìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True):
            goto("input")
    with a3:
        if st.button("ì‹œì‘ í™”ë©´", use_container_width=True):
            reset_all("start")


# -------------------------
# Router
# -------------------------
step = st.session_state.step
if step == "start":
    render_start()
elif step == "input":
    render_input()
elif step == "analyze":
    render_analyze()
elif step == "result":
    render_result()
else:
    reset_all("start")




